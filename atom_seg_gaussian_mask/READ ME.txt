this model is trained using atomsegmentation_bupt_gaussianmask.
and loss function is 100 based chi-square loss.



# train.py

from __future__ import print_function
from math import log10
import numpy as np 
import random
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
from unet_temp import UNet 
#from unet_nopooling import UNet 
from AtomicDataLoader import get_training_set, get_test_set
import torchvision
import matplotlib.pyplot as plt


class KaiLoss(nn.Module):
    def __init__(self):
        super(KaiLoss, self).__init__()

    def forward(self, output, target):
        length = output.size()[2] * output.size()[3]
        temp1 = torch.sum(torch.pow((output - target),2)/(target + torch.max(target)/100), dim = 3)
        
        temp2 = torch.sum(temp1, dim = 2)
        temp3 = torch.sum(temp2, dim = 1)/length

        return torch.mean(temp3)

# training settings
# 
class option:
	def __init__(self):
		self.cuda = True
		self.testBatchSize = 4
		self.batchSize = 4
		self.nEpochs = 200
		self.lr = 0.01
		self.threads = 4
		self.seed = 123
		self.size = 256
		self.remsize = 20
		self.colordim = 1
		self.target_mode = 'seg'
		self.pretrain_net = ""

opt = option()

cuda = opt.cuda
if cuda and not torch.cuda.is_available():
	raise Exception("No GPU found, please run without --cuda")

torch.manual_seed(opt.seed)
if cuda:
	torch.cuda.manual_seed(opt.seed)

print('===> Loading data')
train_set = get_training_set(opt.size, 
					         target_mode = opt.target_mode, 
					         colordim = opt.colordim)
test_set = get_test_set(opt.size, 
					         target_mode = opt.target_mode, 
					         colordim = opt.colordim)
training_data_loader = DataLoader(dataset = train_set, 
								  num_workers = opt.threads,
								  batch_size = opt.batchSize,
								  shuffle = True)
testing_data_loader = DataLoader(dataset = test_set, 
								 num_workers = opt.threads,
								 batch_size = opt.testBatchSize,
								 shuffle = False)


print('===> Building unet')

unet = UNet()

criterion = KaiLoss()

if cuda:
	unet = unet.cuda()
	print(unet)
	criterion = criterion.cuda()

pretrained = False

optimizer = optim.SGD(unet.parameters(), lr = opt.lr, momentum = 0.9, weight_decay = 0.0001)
print('===> Training unet')



def train(epoch):

	epoch_loss = 0

	for iteration, (batch_x, batch_y) in enumerate(training_data_loader):
#		randH = random.randint(0, opt.remsize)
#		randW = random.randint(0, opt.remsize)

		input  = Variable(batch_x)
#		target = Variable(batch[1][:, :, target_gap : target_gap + target_size,
#								   target_gap : target_gap + target_size])
#		target = Variable(batch_y.long())
#		target = target.view([target.size()[0], 256, 256])

		target = Variable(batch_y)

		if cuda:
			input  = input.cuda()
			target = target.cuda()
		input  = unet(input)
#		input = (input - input.min())/(input.max() - input.min())


		loss = criterion(input, target)
		epoch_loss += (loss.data[0])
		optimizer.zero_grad()
		loss.backward()
		optimizer.step()

		if iteration % 50 is 0:
			print("===> Epoch[{}]({}/{}) : Loss: {:.4f}".format(epoch, iteration, len(training_data_loader), loss.data[0]))

#	result = torch.max(input, 1)
	result1 = input.cuda()


	imgout = torch.cat([target, result1], 0)
#	imgout = imgout.view([imgout.size()[0], 1, imgout.size()[1], imgout.size()[2]])

#	imgout = torch.cat([target.data, input.data], 0)
	torchvision.utils.save_image(imgout.data, "/home/student/Documents/u-net_pytorch/atomsegmentation_bupt_new/kai_epochs/epoch_" + str(epoch) + '.jpg')
	print("===> Epoch {} Complete: Avg. Loss: {:.4f}".format(epoch, epoch_loss / len(training_data_loader)))

	return epoch_loss/len(training_data_loader)
	
	


def test():
	totalloss = 0
	for batch in testing_data_loader:
		input = Variable(batch[0], volatile = True)
#		target =  Variable(batch[1][:, :, 
#						   target_gap : target_gap + target_size,
#						   target_gap : target_gap + target_size], 
#						   volatile = True)
#		target =  Variable(batch[1][:, :, :, :].long(),volatile = True)
#		target = target.view([target.size()[0], 256, 256])
		target =  Variable(batch[1][:, :, :, :],volatile = True)
		
		if cuda:
			input = input.cuda()
			target = target.cuda()


		prediction = unet(input)

		loss = criterion(prediction, target)
		totalloss += loss.data[0]
	print("===> Avg. test loss: {:,.4f} dB".format(totalloss / len(testing_data_loader)))
	return totalloss / len(testing_data_loader)


def checkpoint(epoch):
	model_out_path = "/home/student/Documents/u-net_pytorch/atomsegmentation_bupt_new/kai_checkpoint/model_epoch_{}.pth".format(epoch)
	torch.save(unet.state_dict(), model_out_path)
	print("Checkpoint saved to {}.".format(model_out_path))

plt.ion()

count = 1

for epoch in range(1, opt.nEpochs + 1):
	avg_loss = train(epoch)

	plt.scatter(epoch, avg_loss)
	plt.pause(0.05)

	if epoch % 20 is 0:
		checkpoint(epoch)

	cur_loss = test()
	if epoch == 1:
		pre_loss = cur_loss
	else:
		if pre_loss <= cur_loss:
			count = count + 1
		else:
			count = 1
	if count >= 20:
		break
	pre_loss = cur_loss

checkpoint(epoch)

plt.ioff()
plt.show()